官方文档：https://spark.apache.org/docs/latest/tuning.html 中大概介绍了三种调优方式：
- 数据序列化
- 内存调优
- 其他
## 数据序列化
- [x] [[为什么对象序列化速度影响Spark的计算速度]] #leopard/性能调优 ✅ 2024-03-04
Spark提供了两种序列化库：
- Java序列化：默认方式，实现了java.io.Serializable的类即可进行Java序列化，慢且序列化出来的格式大
- Kryo 序列化：比Java序列化快（快10倍），但不支持所有 `Serializable` 类型，并且需要提前注册将在程序中使用的类以获得最佳性能。如果不注册，也是可以使用的，但必须为每个对象存储完整的类名，比较浪费。使用Kryo序列化需要使用 SparkConf 初始化作业并调用 conf.set("spark.serializer","org.apache.spark.serializer.KryoSerializer")来切换到使用Kryo。
## 内存调优
在Spark中，存储可以分为两类：执行和存储。两者共享统一的区域（M），没有“存储”需要时，“执行”可以获取所有可用内存，没有“执行”需要时，“存储”可以获取所有可用内存。必要时，“执行”可以逐出“存储”，不过可以配置一个值R（R是M的一个子区域），R里面的“存储”永远不会被逐出。
### 那么，什么是“存储”需要，什么是“执行”需要？
当需要进行跨集群cache、传播内部数据时，会使用“存储”内存。
当需要进行shuffle、join、sort、agg时，会使用“执行”内存。
### spark.memory.fraction
spark.memory.fraction参数可以控制M的大小，M = spark.memory.fraction * JVM堆空间。其中spark.memory.fraction值默认是0.6，其余空间 (40%) 保留用于用户数据结构、Spark 中的内部元数据，以及在稀疏和异常大的记录情况下防止 OOM 错误。
### spark.memory.storageFraction
spark.memory.storageFraction参数可以控制R的大小，R是M的内部子区域，R = M * spark.memory.storageFraction，其中spark.memory.storageFraction默认值是0.5。
### 那么，如何确定数据集所需消耗的内存？
对于dataframe来说，将df缓存后查看web ui里面的storage页面即可。
```python
df = df[
    ["code", "orderprice"]
]  # 存储scan了三列，多了一个ts列，是否可以不scan ts列？
df.spark.cache()
```
![[Pasted image 20240305105932.png]]
上图说明，df所需消耗的内存是434.6MB。
[[Spark如何减少内存消耗]]
